{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fa9f84",
   "metadata": {},
   "source": [
    "---\n",
    "# 03_training_and_evaluation.ipynb\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91952ca8",
   "metadata": {},
   "source": [
    "This notebook provides a complete end-to-end example of how to train and evaluate a model using the `ModularML` framework. It demonstrates how to:\n",
    "\n",
    "1. Define a `ModelGraph` with one or more trainable model stages\n",
    "2. Wrap training logic in a `TrainingPhase`\n",
    "3. Run training using the `Experiment` container\n",
    "4. Evaluate the trained model using `EvaluationPhase`\n",
    "5. Visualize predictions against ground truth\n",
    "\n",
    "We use a simple example in which a fully connected MLP regressor is trained to estimate target values from pulse charge features of a battery dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86108012",
   "metadata": {},
   "source": [
    "We will be utilizing the FeatureSet and ModelStages created in the prior two notebooks. \n",
    "If you haven't already, please go through the following examples:\n",
    "* [01_featureset_basics.ipynb](./01_featureset_basics.ipynb)\n",
    "* [02_modelgraph_basics.ipynb](./02_modelgraph_basics.ipynb)\n",
    "\n",
    "\n",
    "Let's reload the pre-processed FeatureSet and ModelStages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import modularml as mml\n",
    "from modularml.core import FeatureSet, ModelGraph, ModelStage, Optimizer\n",
    "from modularml.models.torch import SequentialMLP\n",
    "\n",
    "FILE_FEATURE_SET = Path(\"downloaded_data/charge_samples.joblib\")\n",
    "charge_samples = FeatureSet.load(FILE_FEATURE_SET)\n",
    "charge_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb5b98",
   "metadata": {},
   "source": [
    "We will start this example with a simple 3-layer MLP model.\n",
    "It pulls features from the 'ChargePulseFeatures' FeatureSet.\n",
    "\n",
    "We can confirm the target output size with `FeatureSet.target_shape_spec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4256a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(charge_samples.target_shape_spec)\n",
    "\n",
    "ms_regressor = ModelStage(\n",
    "    model=SequentialMLP(output_shape=(1, 1), n_layers=3, hidden_dim=32),\n",
    "    label=\"Regressor\",\n",
    "    upstream_node=charge_samples,\n",
    "    optimizer=Optimizer(\"adam\", lr=1e-3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd36fb2",
   "metadata": {},
   "source": [
    "The ModelGraph is constructed via a list of ModelStages and FeatureSets.\n",
    "\n",
    "Calling `build_all` ensure all ModelStages instantiate their underlying NN components, and infer any missing input/output shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = ModelGraph(nodes=[charge_samples, ms_regressor])\n",
    "mg.build_all()\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783675c",
   "metadata": {},
   "source": [
    "Now that the `ModelGraph` is built, we are ready to move on to the core ModularML training logic and central `Experiment` container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea98a297",
   "metadata": {},
   "source": [
    "## Define a Training Phase\n",
    "\n",
    "Training in ModularML is handled through a `TrainingPhase`. It is a declarative container that defines how to train the ModelGraph.\n",
    "\n",
    "If has the following initiallization arguments:\n",
    "* `label`: a name (str) to assigned to this training phase for logging (e.g., \"pretrain_encoder\").\n",
    "* `losses`: a list of `AppliedLoss` objects\n",
    "* `samplers`: a mapping of `FeatureSampler`s to FeatureSets in ModelGraph.\n",
    "* `batch_size`: the batch size to use across all batches in a single training phase.\n",
    "* `n_epochs`: the number of training epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9531ec",
   "metadata": {},
   "source": [
    "Let's start with the `AppliedLoss` class.\n",
    "It defines the loss function and how it should be applied to the ModelGraph.\n",
    "\n",
    "For example, let's assume we are using a TripletSampler, which produces 'anchor', 'positive', and 'negative' sample pairs.\n",
    "We would have a corresponding TripletLoss that takes in the ModelStage outputs for each of these sample roles. \n",
    "\n",
    "``` python\n",
    "def triplet_loss(anchor, positive, negative): ...\n",
    "```\n",
    "\n",
    "To apply this triplet_loss to a ModelStage's output (assume it's called 'encoder'), we would define an AppliedLoss where the `inputs` argument maps the loss function keyword arguments to the available samples and roles.\n",
    "\n",
    "\n",
    "``` python\n",
    "ap = AppliedLoss(\n",
    "\tlabel='my_triplet_loss',\n",
    "\tloss=Loss(loss_function=triplet_loss),\n",
    "\tinputs={\n",
    "\t\t'anchor': \"ChargePulseFeatures.features.anchor\",\n",
    "\t\t'positive': \"ChargePulseFeatures.features.negative\",\n",
    "\t\t'negative': \"ChargePulseFeatures.features.positive\",\n",
    "\t}\n",
    ")\n",
    "```\n",
    "\n",
    "The `inputs` key-value following the following schema: \n",
    "* the key must be a keyword argument of the loss_function. If the loss function only accepts positional arguments, keys can take the form of integers or string equivalents (e.g., `{\"0\": ..., }` or `{0: ..., }`)\n",
    "* the value is a period (.)-parsed string with the following pattern: `'node.attribute.role'`:\n",
    "  * `node` is the label of a FeatureSet or ModelStage contained in ModelGraph\n",
    "  * `attribute` is one of the following: ['features',  'targets', 'output']\n",
    "    * 'features' and 'targets' only apply if `node` is a FeatureSet\n",
    "    * 'output' is used if `node` is a ModelStage\n",
    "  * `role` is a sample key defined by the FeatureSampler used. E.g, a TripletSampler creates 'anchor', 'positive', and 'negative' roles. A simple FeatureSampler has only a 'default' role. If `role` is ommited (e.g., `'node.attribute'`), then the role is assumed to be 'default'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c06add",
   "metadata": {},
   "source": [
    "For our first example, we only have a single MLP ModelStage where our task is estimating battery state-of-health. \n",
    "\n",
    "We will start with only a single mean-squared-error loss function applied to the regressor outputs.\n",
    "Common loss functions are easily accessible using the `name` and `backend` attribute of the `Loss` class.\n",
    "See the documentation for a more detailed description on available losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modularml.core import AppliedLoss, Loss\n",
    "\n",
    "mse_loss = AppliedLoss(\n",
    "    label=\"MyAppliedLoss\",\n",
    "    loss=Loss(name=\"mse\", backend=mml.Backend.TORCH),\n",
    "    all_inputs={  # The PyTorch MSELoss only accept positional arguments\n",
    "        \"0\": \"ChargePulses.targets\",\n",
    "        \"1\": \"Regressor.output\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c336156",
   "metadata": {},
   "source": [
    "The next set of `TrainingPhase` attributes define the sampling configuration.\n",
    "\n",
    "Since we only have one FeatureSet (`\"ChargePulseFeatures\"`) in our ModelGraph, we only need to create one FeatureSampler.\n",
    "Our `mse_loss` only need a single sample role (\"default\"), so we can stick with just a simple FeatureSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e013c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modularml.core import SimpleSampler\n",
    "\n",
    "sampler = SimpleSampler(\n",
    "    shuffle=True,\n",
    "    stratify_by=[\"pulse_soc\"],\n",
    "    seed=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16434b48",
   "metadata": {},
   "source": [
    "The base `FeatureSampler` support grouping and stratification via the `group_by` and `stratify_by` parameters.\n",
    "\n",
    "Using `stratify_by=[\"pulse_soc\"]` ensures that every batch created from the feature set contains an equal distribution of pulse states of charge (SOC).   \n",
    "\n",
    "Attaching the sampler to `TrainingPhase` is done with a key:value entry in a dictionary. \n",
    "The key must be the name of FeatureSet or FeatureSubset (e.g., 'ChargePulseFeatures' or 'ChargePulseFeatures.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modularml.core import TrainingPhase\n",
    "\n",
    "phase1 = TrainingPhase(\n",
    "    label=\"train_phase\",\n",
    "    losses=[mse_loss],\n",
    "    train_samplers={\"ChargePulses.train\": sampler},\n",
    "    val_samplers={\"ChargePulses.val\": sampler},\n",
    "    batch_size=32,\n",
    "    n_epochs=10,\n",
    "    early_stop_patience=10,\n",
    "    early_stop_metric=\"val_loss\",\n",
    "    early_stop_min_delta=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c480e26",
   "metadata": {},
   "source": [
    "We now have a fully-configured TrainingPhase, that utilizes the 'train' subset of the 'ChargePulseFeatures' FeatureSet.\n",
    "An MSE loss is applied to the single MLP regressor ModelStage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a69350",
   "metadata": {},
   "source": [
    "## Create and Run the Experiment\n",
    "\n",
    "The `Experiment` container manages both training and evaluation phases. \n",
    "It takes a `ModelGraph` and one or more phases (training or evaluation).\n",
    "\n",
    "Calling `.run()` will automatically execute all training phases and manage phase-level loss computation, sampling, and optimizer stepping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the experiment\n",
    "from modularml.core import Experiment\n",
    "\n",
    "exp = Experiment(\n",
    "    graph=mg,\n",
    "    phases=[phase1],\n",
    ")\n",
    "\n",
    "# Calling run() will execute all phases in Experiment.phases\n",
    "# These are run in the order they are provided\n",
    "res = exp.run_training_phase(phase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = res.plot_losses()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c195b70",
   "metadata": {},
   "source": [
    "While we could pass multiple stage right to Experiment during construction, it is sometimes useful during the exploratory stage to run one stage at a time and then evaluate the model.\n",
    "\n",
    "This can be achieved by using the `run_training_phase` or `run_evaluation_phase` methods, which both take in a single phase to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e110d538",
   "metadata": {},
   "source": [
    "# Define and Run Evaluation Phases\n",
    "\n",
    "Evaluation of the ModelGraph utilizes a separate `EvaluationPhase` class, which provides functionality catered explciity to ModelGraph evaluation and not training. \n",
    "\n",
    "`EvaluationPhase` utilizes a very similar constructor (minus `n_epochs`), and the `losses` argument is optional.\n",
    "\n",
    "Here, we define three `EvaluationPhase` objects for the train, val, and test splits of our 'ChargePulseFeatures' FeatureSet. \n",
    "Each uses the same MSE loss but samples from different subsets of the dataset during each EvaluationPhase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modularml.core import EvaluationPhase\n",
    "\n",
    "all_results = {}\n",
    "val_phase = None\n",
    "for subset in [\"train\", \"val\", \"test\"]:\n",
    "    val_phase = EvaluationPhase(\n",
    "        label=f\"val_{subset}\",\n",
    "        samplers={f\"ChargePulses.{subset}\": sampler},\n",
    "        batch_size=64,\n",
    "        losses=[mse_loss],\n",
    "    )\n",
    "    all_results[subset] = exp.run_evaluation_phase(val_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from modularml.visualization.common.parity_plot import plot_parity_from_node_outputs\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    figsize=(2.3 * len(all_results), 2),\n",
    "    ncols=len(all_results),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "for i, subset in enumerate(all_results.keys()):\n",
    "    val_phase = EvaluationPhase(\n",
    "        label=f\"val_{subset}\",\n",
    "        samplers={f\"ChargePulses.{subset}\": sampler},\n",
    "        batch_size=64,\n",
    "        losses=[mse_loss],\n",
    "    )\n",
    "    val_res = exp.run_evaluation_phase(val_phase)\n",
    "    # fig, axes[i] = val_res.plot_parity(\"Regressor\", ax=axes[i], plot_style='kde', kde_levels=5, vmin=0.5, alpha=1.0)\n",
    "\n",
    "    df_unscaled = exp.inverse_transform_node_outputs(val_res.outputs, node=\"Regressor\")\n",
    "    pred = np.vstack(df_unscaled[\"output\"].values).reshape(-1)\n",
    "    true = np.vstack(df_unscaled[\"target\"].values).reshape(-1)\n",
    "    fig, axes[i] = plot_parity_from_node_outputs(\n",
    "        outputs=df_unscaled,\n",
    "        node=\"Regressor\",\n",
    "        ax=axes[i],\n",
    "        plot_style=\"kde\",\n",
    "        kde_levels=5,\n",
    "        vmin=1e-4,\n",
    "        alpha=1.0,\n",
    "    )\n",
    "    mse = mean_squared_error(true, pred)\n",
    "    mape = mean_absolute_percentage_error(true, pred) * 100\n",
    "    axes[i].annotate(f\"MSE={mse:.03f}\", xy=(0.97, 0.05), xycoords=\"axes fraction\", ha=\"right\", fontsize=8)\n",
    "    axes[i].annotate(f\"MAPE={mape:.03f}\", xy=(0.97, 0.12), xycoords=\"axes fraction\", ha=\"right\", fontsize=8)\n",
    "    axes[i].set_title(subset, fontsize=10)\n",
    "    if i > 0:\n",
    "        axes[i].set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b6fa7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "- Build a ModelGraph with PyTorch backends\n",
    "- Define training and evaluation phases\n",
    "- Manage end-to-end execution with the Experiment container\n",
    "- Visualize model performance\n",
    "\n",
    "\n",
    "This concludes the **03_training_and_evaluation.ipynb** notebook.\n",
    "\n",
    "The next tutorial explain `Experiment` tracking and rapid iteration: *...coming soon*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
