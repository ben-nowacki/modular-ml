{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552cc21a",
   "metadata": {},
   "source": [
    "---\n",
    "# 02_modelgraph_basics.ipynb\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33fa5ee",
   "metadata": {},
   "source": [
    "## Building a ModelGraph\n",
    "\n",
    "One of the most powerful aspects of ModularML is its `ModelGraph` abstraction, which represents a directed-acyclic-graph (DAG) of computation. This structure allows multiple `ModelStage` instances to be flexibly connected into a larger model pipeline.\n",
    "\n",
    "Each `ModelStage` can use any supported backend, such as PyTorch, TensorFlow/Keras, or Scikit-learn. This enables the creation of complex multi-objective modeling workflows using a unified interface.\n",
    "\n",
    "In this example, we demonstrate a two-stage modeling pipeline: a CNN encoder processes input voltage features into a latent embedding, followed by an MLP regressor that estimates the battery state-of-health (SOH) from this embedding.\n",
    "\n",
    "ModularML provides pre-built classes for commonly used model types such as sequential CNNs and MLPs. While we use those here, any custom model can be integrated by subclassing `modularml.BaseModel` and implementing the required methods.\n",
    "\n",
    "Let's import the necessary components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b71a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modularml as mml\n",
    "from modularml.core import FeatureSet, ModelGraph, ModelStage, Optimizer\n",
    "from modularml.models.torch import SequentialCNN, SequentialMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec115725",
   "metadata": {},
   "source": [
    "We will be utilizing the FeatureSet created from the [01_featureset_basics.ipynb](./01_featureset_basics.ipynb) notebook. \n",
    "\n",
    "Let's reload that FeatureSet and underlying FeatureTransforms from the `.joblib` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "FILE_FEATURE_SET = Path(\"downloaded_data/charge_samples.joblib\")\n",
    "charge_samples = FeatureSet.load(FILE_FEATURE_SET)\n",
    "charge_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b539969",
   "metadata": {},
   "source": [
    "Now we can start creating our `ModelStages`.\n",
    "\n",
    "The `modularml.models` module provides convenient, pre-built implementations such as `SequentialCNN` and `SequentialMLP`, which allow for rapid prototyping of convolutional and dense architectures with configurable layer depth and hidden sizes. Please refer to the module documentation for a full list of available initialization parameters.\n",
    "\n",
    "A key feature of the `ModelStage` abstraction is its support for **lazy shape inference**. Input and output shapes do not need to be explicitly specified during model construction. Instead, ModularML dynamically infers the required shapes at runtime based on how FeatureSets and other ModelStages are connected in the ModelGraph.\n",
    "\n",
    "While input shape inference is automatic, it is generally advisable to specify the desired output shape for clarity and to avoid unintended behavior.\n",
    "\n",
    "To construct a `ModelStage`, the following arguments are required:\n",
    "\n",
    "* `model`: The machine learning model to be wrapped, which must inherit from `BaseModel`.\n",
    "\n",
    "* `label`: A unique string identifier for the stage.\n",
    "\n",
    "* `upstream_node`: The nodes that feed into this stage. Can be the label (str) of such nodes, or the nodes themselves.\n",
    "\n",
    "* `optimizer`: An optional `Optimizer` object used for training, required if the model parameters are to be updated during optimization. Note that we can define an Optimzer at the stage-level (if each stage is using a different backend) or at the graph-level (all stages must be the same backend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c345273",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_encoder = ModelStage(\n",
    "    model=SequentialCNN(output_shape=(1, 32), n_layers=2, hidden_dim=16, flatten_output=True),\n",
    "    label=\"Encoder\",\n",
    "    upstream_node=\"ChargePulses\",  # Note that we could also pass the charge_samples object itself\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4632a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_regressor = ModelStage(\n",
    "    model=SequentialMLP(output_shape=(1, 1), n_layers=2, hidden_dim=16),\n",
    "    label=\"Regressor\",\n",
    "    upstream_node=ms_encoder,  # Here, we pass the encoder object itself, but we could also use the string 'Encoder'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f129844",
   "metadata": {},
   "source": [
    "With both stages defined, we construct the `ModelGraph`. \n",
    "\n",
    "`ModelGraph` requires only one argument:\n",
    "\n",
    "* `nodes`: A list of `ModelStage` or `FeatureSet` instances to incorporate into this ModelGraph. The order of the nodes does not matter, as long as all required inputs are included.\n",
    "\n",
    "The ModelGraph will handle all data routing, shape inference, and connection validation with the `.build_all()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = ModelGraph(\n",
    "    nodes=[charge_samples, ms_encoder, ms_regressor],\n",
    "    optimizer=Optimizer(name=\"adam\", backend=mml.Backend.TORCH),\n",
    ")\n",
    "mg.build_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33fd2d",
   "metadata": {},
   "source": [
    "We see that the missing input_shapes have been correctly inferred to match `charge_samples.feature_shape` and encoder output shape.\n",
    "\n",
    "\n",
    "ModelGraph has another useful validation function called `dummy_forward`.\n",
    "This performs a full forward pass of all connected stages with dummy batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stage_results = mg.dummy_foward(batch_size=8)\n",
    "all_stage_results[\"Regressor\"].feature_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd884798",
   "metadata": {},
   "source": [
    "Great. We have a fully functional ModelGraph that correctly outputs a target with shape (1,1).\n",
    "\n",
    "Although this ModelGraph is very simple, as the number of nodes increase, it can be difficult to keep track of how all stages are connected.\n",
    "We can visuallize these node connections with the `visualize` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc06917",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f248781",
   "metadata": {},
   "source": [
    "---\n",
    "### Using `ModelGraph.insert`\n",
    "\n",
    "Instead of rebuilding a whole `ModelGraph` with \n",
    "```python\n",
    "    ModelGraph(nodes=[...], ...)\n",
    "```\n",
    "you can modify an existing graph with the `insert` method.\n",
    "\n",
    "The method signature is:\n",
    "```python\n",
    "    ModelGraph.insert(node, before=None, after=None, inplace=True)\n",
    "```\n",
    "Arguments:\n",
    "* `node`: the new graph node (FeatureSet, ModelStage, etc.) to insert.\n",
    "* `before`: name (or list of names) of downstream node(s) that the new node should feed into.\n",
    "* `after`: name (or list of names) of upstream node(s) whose outputs should feed into the new node.\n",
    "* `inplace`: if True, modifies the current graph directly; if False, returns a new graph with the insertion.\n",
    "\n",
    "How it rewires the graph:\n",
    "* If both after and before are provided:\n",
    "  - Inserts the new node between them, replacing the existing connection.\n",
    "* If only before is given:\n",
    "  - Redirects all inputs to the specified before node so they first pass through the new node.\n",
    "* If only after is given:\n",
    "  - Redirects all outputs from the specified after node so they flow through the new node.\n",
    "\n",
    "This is useful for quickly adding new head nodes, intermediate model layers, or feature sets without re-instantiating the entire ModelGraph.\n",
    "\n",
    "Let's start with a slightly more complex ModelGraph to better visualize how connections are modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modularml.core import ConcatStage\n",
    "\n",
    "nodes = [\n",
    "    charge_samples,\n",
    "    ModelStage(label=\"Encoder A\", model=SequentialMLP(output_shape=(1, 32)), upstream_node=charge_samples),\n",
    "    ModelStage(label=\"Encoder B\", model=SequentialMLP(output_shape=(1, 32)), upstream_node=charge_samples),\n",
    "    ConcatStage(label=\"Merge\", upstream_nodes=[\"Encoder A\", \"Encoder B\"], axis=1),\n",
    "    ModelStage(label=\"Regressor\", model=SequentialMLP(output_shape=(1, 1)), upstream_node=\"Merge\"),\n",
    "]\n",
    "mg = ModelGraph(nodes=nodes, optimizer=Optimizer(name=\"adam\", backend=mml.Backend.TORCH))\n",
    "mg.build_all()\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a94f0",
   "metadata": {},
   "source": [
    "**Scenario 1: provided after and before**\n",
    "\n",
    "Here we insert a new node \"Before+After\" between our FeatureSet and \"Encoder A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node = ModelStage(label=\"Before+After\", model=SequentialMLP(output_shape=(1, 64)), upstream_node=\"Encoder A\")\n",
    "mg.insert(node=new_node, before=\"Merge\", after=\"Encoder A\", inplace=True)\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5725a",
   "metadata": {},
   "source": [
    "We see that it is inserted between the specified nodes, replacing the existing connection.\n",
    "\n",
    "We'll remove it before exploring the alternative insert methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1bbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.remove(\"Before+After\")\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1802f",
   "metadata": {},
   "source": [
    "**Scenario 2: provided only before**\n",
    "\n",
    "We could've achieved the same result using only the 'before' argument.\n",
    "\n",
    "The difference with this approach only arises when the node we are inserting before has multiple inputs.\n",
    "In that case, ***all inputs*** get rewired to pass through this new node whereas specifying before and after will only rewire the single connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node = ModelStage(label=\"Before\", model=SequentialMLP(output_shape=(1, 64)), upstream_node=\"ChargePulses\")\n",
    "mg.insert(node=new_node, before=\"Encoder A\", inplace=True)\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927a785",
   "metadata": {},
   "source": [
    "As expected, we got the same result as using before and after.\n",
    "\n",
    "If we instead insert before the 'Merge', we'll see how all inputs get rewired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faadcaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.remove(\"Before\")\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node = ConcatStage(label=\"Before\", upstream_nodes=[\"Encoder A\", \"Encoder B\"], axis=1)\n",
    "mg.insert(node=new_node, before=\"Merge\", inplace=True)\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b775aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.remove(\"Before\")\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e75b6b",
   "metadata": {},
   "source": [
    "**Scenario 3: provided only after**\n",
    "\n",
    "Similarly, specifying only 'after' results in shifting all downstream connections to the new node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node = ModelStage(label=\"After\", model=SequentialMLP(output_shape=(1, 64)), upstream_node=\"ChargePulses\")\n",
    "mg.insert(node=new_node, after=\"ChargePulses\", inplace=True)\n",
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70269ade",
   "metadata": {},
   "source": [
    "We see that the two downstream connection of 'ChargePulses' were moved onto the new 'After' ModelStage.\n",
    "Now 'ChargePulses' only outputs into 'After'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c5140",
   "metadata": {},
   "source": [
    "This concludes the **02_modelgraph_basics** notebook.\n",
    "\n",
    "The next tutorial explain the `Experiment` container and ModelGraph training/evaluation logic: [03_training_and_evaluation.ipynb](./03_training_and_evaluation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envModularML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
